# Advanced AI: Transformers for Computer Vision

Transformers are quickly becoming the go-to architecture for many computer vision tasks. If you work in the field, it’s a must-have skill to keep on hand in your AI toolkit. In this course, AI consultant Jonathan Fernandes takes you on a deep dive into the world of transfer learning and transformer model architecture.

Explore the basics of computer vision, image datasets, preprocessing, and image fine-tuning, with hands-on examples and easy-to-follow demonstrations using Google Colab and the Hugging Face library. Discover tips and practical strategies for model training and testing as you go, building out your skill set with the popular inference modeling tools Gradio and Hugging Face Spaces. By the end of this course, you’ll be prepared to design and train larger, more advanced, more sophisticated language models.

## Instructions
If you're relatively new to Transformers and working with code, then a good starting point is using some of the Python packages developed by Hugging Face. Hugging Face is a company that gives you access to pre-trained models from their model hub. . We'll need to set up a Hugging Face account and access the Google CoLab notebook. There is a detailed walkthru in the LinkedIn Learning course videos.

## Installing
1. To use these exercise files, you must have the following installed:
	- Hugging Face account
	- Google CoLab account
2. Clone this repository into your local machine using the terminal (Mac), CMD (Windows), or a GUI tool like SourceTree.
